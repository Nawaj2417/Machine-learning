{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Explain the difference between  simple linear regression and multiple linear regression. provide an \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b29fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans: simple linear regression is a stastical technique used to model the relationship between two variable\n",
    "     one is independent variable (x) and another is dependent variable (Y).The goal of simple linear regression\n",
    "        is to find the best-fitting line that minimizes the overall distance between the observed data  points\n",
    "        and the line.\n",
    "        \n",
    "        similarly, multiple linear regression extends the concept of linear regression to more than one independent\n",
    "        variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d25622",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given\n",
    "dataset?\n",
    "\n",
    "Ans: linear regression relies on several assumption for its validity. Here the key assumptions of linear\n",
    "    regression: linearity, independence, Homosecedasticity, Normality etc.\n",
    "        \n",
    "    To check whether these assumptions hold in a given dataset, we can perform the following methods check:\n",
    "        1. Residual Analysis\n",
    "        2.Residual plots\n",
    "        3. Normality test\n",
    "        4. Cook's distance\n",
    "        5. scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a\n",
    "real-world scenario.\n",
    "\n",
    "Ans: In linear regression model, the slope and intercept have specific interpretations, an example of using a\n",
    "    world scenario are : To provide an example, let's consider a real-world scenario of predicting house prices based on their size (in square feet). We collect data on various houses, including their sizes and corresponding sale prices. We can use a linear regression model to estimate the relationship between house size and price.\n",
    "\n",
    "In this case, the independent variable is the house size (in square feet), and the dependent variable is the house price (in dollars). The linear regression model can be represented as:\n",
    "\n",
    "Price = Intercept + Slope * Size\n",
    "\n",
    "The intercept represents the estimated price of a house when its size is zero, which is not meaningful \n",
    "in this context. However, the slope represents the estimated change in the house price for each \n",
    "additional square foot of size.\n",
    "\n",
    "Suppose the linear regression analysis yields the following results: Intercept = $50,000 and \n",
    "    Slope = $100. It means that, according to the model, the estimated price of a house increases \n",
    "    by $100 for each additional square foot of size. The intercept of $50,000 suggests that even a\n",
    "    house with zero square footage would have a starting price of $50,000, which is likely an\n",
    "    unrealistic scenario.\n",
    "\n",
    "So, if we have a house with a size of 1,500 square feet, we can estimate its price using the linear\n",
    "regression model:\n",
    "\n",
    "Price = $50,000 + $100 * 1,500\n",
    "Price = $50,000 + $150,000\n",
    "Price = $200,000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ac286",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explain the concept of gradient descent. How is it used in machine learning.\n",
    "Ans: Gradient descent is an iterative optimization algorithm used in machine learning to\n",
    "    minimize the cost function of a model. It is particularly useful in training models with\n",
    "    large amounts of data and complex parameter spaces. The goal of gradient descent is to\n",
    "    find the set of parameters that minimize the cost function and make the model perform optimally.\n",
    "\n",
    "The concept of gradient descent revolves around the idea of taking steps in the direction of steepest\n",
    "descent (negative gradient) to gradually reach the minimum of the cost function. It calculates the\n",
    "gradient (partial derivatives) of the cost function with respect to each parameter and updates the\n",
    "parameter values in the opposite direction of the gradient.\n",
    "\n",
    "Here's a step-by-step explanation of the gradient descent process:\n",
    "\n",
    "    Initialization: Start by initializing the model's parameters with random values or predetermined \n",
    "        values.\n",
    "\n",
    "    Compute the cost function: Evaluate the cost function using the current parameter values. \n",
    "        The cost function quantifies the difference between the model's predicted output and the actual output.\n",
    "\n",
    "    Calculate the gradient: Compute the partial derivatives of the cost function with respect to \n",
    "        each parameter. The gradient indicates the direction of the steepest increase of the cost \n",
    "        function.\n",
    "\n",
    "    Update the parameters: Adjust the parameter values by subtracting a fraction of the gradient\n",
    "        multiplied by a learning rate (step size). The learning rate determines the size of the\n",
    "        steps taken in each iteration.\n",
    "\n",
    "    Repeat steps 2 to 4: Iterate through steps 2 to 4 until convergence or a predefined number of \n",
    "        iterations. Convergence occurs when the parameter values reach a point where further updates\n",
    "        to the parameters yield negligible improvement in the cost function.\n",
    "\n",
    "    Final parameter values: Once the gradient descent algorithm converges or reaches the maximum\n",
    "        number of iterations, the final parameter values are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc69233",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "Ans: Multiple linear regression is an extension of simple linear regression that allows for the analysis \n",
    "    of the\n",
    "    relationship between a dependent variable and multiple independent variables. While simple linear \n",
    "    regression considers the relationship between a dependent variable and a single \n",
    "    independent variable, multiple linear regression incorporates several independent\n",
    "    variables to capture their collective influence on the dependent variable.\n",
    "\n",
    "The multiple linear regression model can be represented as follows:\n",
    "\n",
    "Y = β0 + β1X1 + β2X2 + ... + βn*Xn + ε\n",
    "\n",
    "Where:\n",
    "\n",
    "    Y is the dependent variable (the variable we want to predict).\n",
    "    X1, X2, ..., Xn are the independent variables.\n",
    "    β0 is the intercept (the value of Y when all independent variables are zero).\n",
    "    β1, β2, ..., βn are the coefficients or slopes associated with each independent variable. \n",
    "    They represent the change in Y for a unit change in each corresponding independent variable\n",
    "    while holding other variables constant.\n",
    "    ε is the error term, which captures the unexplained variation in Y not accounted for by the \n",
    "    independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9564d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Explain the concept of multi-collinearity in multiple linear regression. How can you detect and address\n",
    "this issue?\n",
    "\n",
    "Ans: Multi-collinearity refers to a situation in multiple linear regression where two or more\n",
    "    independent variables are highly correlated with each other. \n",
    "    To detect multi-collinearity, there are several methods you can employ:\n",
    "\n",
    "    Correlation matrix: Calculate the correlation coefficients between all pairs of independent\n",
    "        variables. High correlation coefficients (close to 1 or -1) indicate a potential presence \n",
    "        of multi-collinearity.\n",
    "\n",
    "    Variance Inflation Factor (VIF): VIF measures the extent to which the variance of the estimated\n",
    "        regression coefficient is increased due to collinearity. High VIF values (typically greater\n",
    "    than 5 or 10) suggest the presence of multi-collinearity. VIF can be calculated for each\n",
    "        independent variable by regressing it against all the other independent variables.\n",
    "\n",
    "    Eigenvalues or Condition Number: Analyzing the eigenvalues of the correlation matrix or the \n",
    "        condition number can provide insights into the severity of multi-collinearity. If the \n",
    "        eigenvalues are close to zero or the condition number is significantly large, it indicates\n",
    "        a high degree of multi-collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3c360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
