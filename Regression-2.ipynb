{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and \n",
    "what does it represent?\n",
    "\n",
    "Ans: R-squared also known as the coefficient of determnation, is a stastical mesure that assesses\n",
    "    the goodness of fit of a linear regression model. It represents the proportion of the variance\n",
    "    in the dependent variable that is predictable from the independent variables.\n",
    "    \n",
    "    it is calculated by: \n",
    "    R-squared = 1 - (SSR/SST) , where SSR is the sum of squared and actual values and SST is \n",
    "    the total sum of squares ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52727082",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "Ans: Adjusted R-squared is an extension of R-squared that makes into account the number of independent variables in the model and adjusts for the degrees of freedom.\n",
    "\n",
    "Formula:\n",
    "Adjusted R-squared = 1 - [(1 - R-squared) * (n - 1) / (n - k - 1)]\n",
    "\n",
    "The adjusted R-squared value will always be lower or equal to the regular R-squared value. It increases only if the inclusion of an independent variable significantly improves the model's fit, while it decreases if the variable is not helpful or it it introduces noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872975a2",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Ans: Adjusted R-squared is more appropriate to use when comparing models with different numbers of independent variables. Since regular R-squared can increase simply by adding more variables, adjusted R-squared provides a more accurate measure of the model's  performance by adjusting for the number of predicators. It helps in identifying the models that strike a balance between goodness of fit and model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6355ecb",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?\n",
    "\n",
    "Ans: RMSE(Root mean squared error) is the average of the squared differences between the predicted and actual values. it represents the standard deviation of the residuals and is expressed in the same units as the dependent variable.\n",
    "\n",
    "RMSE:  sqrt(sum((predicted - actual)^2) / n)\n",
    "\n",
    "MSE(mean squared Error) is the average of the squared differences between the predicated and actual values. it gives an average measure of the squared errors.\n",
    " Formula: \n",
    " MSE: sum((predicted - actual)^2) / n\n",
    " \n",
    " similarly, MAE(mean absolute error) is the average of the absolute differences between the predicated and actual values. it represents the average magnitude of the errors.\n",
    " MAE : sum(|predicted - actual|) / n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97af95e",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "\n",
    "Ans: Advantages of RMSE, MSE, and MAE as evaluation metrics in regression analysis:\n",
    "\n",
    "They provide a quantitative measure of the model's performance and can be easily interpreted.\n",
    " They take into account the magnitude of errors, not just their direction.\n",
    " They are widely used and well-established metrics in regression analysis.\n",
    "\n",
    "Disadvantages of these metrics:\n",
    "\n",
    " They give equal weight to all errors, which can be problematic if the dataset contains outliers or extreme values.\n",
    " They do not provide information about the specific nature or distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025347e8",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?\n",
    "\n",
    "Ans: Lasso regularization(l1 regularization) is a technique used in linear regression to add a penality term to the loss function.\n",
    "\n",
    "it differ from the Ridge regularization(L2 regularization) in the type of penality term used.\n",
    "Lasso regularization is more appropriate when feature selection is desired, or when it is believed that only a small number of predicators have a substantial impact on the dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112a5bf",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "\n",
    "\n",
    "Ans: Regularized linear models, such as Ridge and Lasso regression, help prevent overfitting in machine learning by adding a penalty term to the loss function. This penalty term limits the complexity of the model and discourages excessive reliance on individual predictors.\n",
    "\n",
    "For example, let's consider a scenario where we have a dataset with a large number of features compared to the number of observations. In a regular linear regression model, the model might try to fit the noise in the data, resulting in overfitting. However, by applying regularization, the model will be penalized for having large coefficients, effectively reducing the impact of less important features and reducing overfitting. Regularization helps to strike a balance between the bias-variance trade-off by shrinking the coefficients and improving the generalization ability of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d3447",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis.\n",
    "\n",
    "Ans: The limitation of regularized linear models are mentioned below:\n",
    "\n",
    "1. Feature interpretation\n",
    "2. Sensitivity to hyperparameters\n",
    "3. violation of assumptions\n",
    "4. Limited impact on collinearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67352d7e",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "\n",
    "Ans : if the focus is on larger errors, Model A may be considered better because it accounts for the squared differences. However, if the emphasis is on the average magnitude of errors, Model B with a lower MAE may be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd00dab",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?\n",
    "\n",
    "\n",
    "Ans: if the goal is feature selection and identifying the most important predictors, Model B (Lasso regularization) may be preferred because it has the potential to set some coefficients exactly to zero, effectively removing irrelavant features from the model. On the other hand, if maintaining all features in the model is desirable, MODel A (Ridge regualrization) might be more appropriate as it does not force coefficients to zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
